{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the AI Services JSON API\n",
    "\n",
    "This Python notebook teaches developers and Digital Accelerators how to call AI Services programmatically.  This can be useful in the initial stages of developing an integration, or when testing an AI model recently deployed to AI Services.  In this notebook, we will submit a single job to AI Services, poll for updates, and fetch the result.\n",
    "\n",
    "To use this notebook, you should be able to run each cell in order.  Two cells need to be tweaked before being run. **These cells are marked with a warning in bold.**  Assuming these cells have been updated, you should be able to run all cells in order, and receive a good result from your AI model.\n",
    "\n",
    "## The Process\n",
    "\n",
    "Even if the underlying AI model is interfaced with in a single HTTP call, the AI Service job API breaks usage into several phases, across several endpoints:\n",
    "\n",
    "1. Create a Job\n",
    "2. Upload document\n",
    "3. Execute Job\n",
    "4. Poll Job Status\n",
    "5. Download Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Software Dependencies\n",
    "\n",
    "Along with the standard library and Jupyter helpers, this model depends on the [requests library](https://pypi.org/project/requests/), which is officially recommended by Python as a high-level HTTP library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "These items must be received from an AI Services representative:\n",
    "- A username.\n",
    "- An application integration GUID.  This is a UUID.\n",
    "- An application token.\n",
    "\n",
    "Your credentials and \"Document Type\" will be for a specific environment.  Select that environment here.  If you're not sure, it's probably \"prod\".\n",
    "\n",
    "**Action: This cell starts with nonsense credentials.  Change this cell to use your own values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"ChangeMe\"\n",
    "APP_GUID = \"d66e7b22-37b6-4db9-8e1e-0a632c45e961\"\n",
    "APP_TOKEN = \"CFFFFD6AE1D844378680614B13905B76\"\n",
    "\n",
    "ENVIRONMENT_ROOTS = {\n",
    "    \"prod\": \"https://ai.pwc.com/api/Nlp\",\n",
    "    \"test\": \"https://ai-tst.pwcinternal.com/api/Nlp\",\n",
    "    \"dev\": \"https://ai-dev.pwcinternal.com/api/Nlp\"\n",
    "}\n",
    "\n",
    "api_root = ENVIRONMENT_ROOTS[\"prod\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "\n",
    "This items must be received from an AI Services representative:\n",
    "- A document type ID.  This is an integer.  \"Document Type\" is a bit of a misnomer, as this number actually identifies the AI asset you will be hitting.\n",
    "\n",
    "Additionally:\n",
    "- The file path to the document you would like to upload to AI Services.\n",
    "- The file path where you would like the output of AI Services to go.\n",
    "\n",
    "**Action: This cell starts with sample configuration to call an AIA Cost Segregation Classifier model.  You can use this configuration with the provided sample input file, or change this cell to use your own values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_TYPE_ID = 1429\n",
    "INPUT_FILE_PATH = \"sample_input_file.csv\"\n",
    "OUTPUT_FILE_PATH = \"output.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP Headers\n",
    "\n",
    "Let's package our credentials into an object that we'll attach to our HTTP calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_services_headers = {\n",
    "    \"Username\": USERNAME,\n",
    "    \"ApplicationIntegrationGuid\": APP_GUID,\n",
    "    \"ApplicationToken\": APP_TOKEN\n",
    "}\n",
    "print(json.dumps(ai_services_headers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test API Connection\n",
    "\n",
    "This cell will test the connection to AI Services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_call = requests.get(f\"{api_root}/GetDocumentTypes\", headers=ai_services_headers, verify=False)\n",
    "status = test_call.status_code\n",
    "if status == 200:\n",
    "    print('Successful API call, your credentials must be good!')\n",
    "else:\n",
    "    print(f'Received unexpected status code {status}, printing response to help you debug')\n",
    "    print(test_call.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-req: Find ID for Output Format\n",
    "\n",
    "If you don't already know your output format, you can learn about them by querying AI Services for information about your AI Asset \"Document Type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_document_types = requests.get(f\"{api_root}/GetDocumentTypes\", headers=ai_services_headers, verify=False)\n",
    "response = get_document_types.json()\n",
    "\n",
    "my_doc_type = next(info for info in response if info.get(\"DocumentTypeId\") == DOC_TYPE_ID)\n",
    "print(json.dumps(my_doc_type, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll grab the output format ID for later.  \n",
    "\n",
    "**Action: You may need to tweak this cell to use the desired output format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = my_doc_type[\"OutputFormats\"][1]\n",
    "output_format_name = output_format[\"DisplayValue\"]\n",
    "output_format_id = output_format[\"OutputFormatId\"]\n",
    "print(f\"The output format is '{output_format_name}' (ID {output_format_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Job\n",
    "\n",
    "By using our document type ID, and specifiying the output format we expect, we can create a new job.  We grab the JobId from the response to use in the remaining steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_job_json = {\n",
    "    \"DocumentTypeId\": DOC_TYPE_ID,\n",
    "    \"OutputFormatId\": output_format_id\n",
    "}\n",
    "create_job = requests.post(f\"{api_root}/CreateJob\", headers=ai_services_headers, verify=False, json=create_job_json)\n",
    "response = create_job.json()\n",
    "print(json.dumps(response, indent=2))\n",
    "\n",
    "job_id = response[\"JobId\"]\n",
    "print(f\"The job ID is {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Document\n",
    "\n",
    "Documents must be uploaded as BASE64 encoded versions of the files.  Uploading a document does not trigger the execution of the job.  Note that you don't _have_ to have a file on disk to upload.  If you're able to encode your data without going to disk, more power to you.\n",
    "\n",
    "Note that _very large_ files may run into some trouble here.  AI Services is loading the base64-encoded file as a string initially, and this can lead to issues at memory allocation time.  If you're regularly breaching 50MB or 100MB in file size, consider yourself warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = os.path.basename(INPUT_FILE_PATH)\n",
    "\n",
    "encoded_input_file = \"\"\n",
    "with open(INPUT_FILE_PATH, \"rb\") as input_file:\n",
    "    encoded_input_file = base64.b64encode(input_file.read()).decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_document_json = {\n",
    "    \"JobId\": job_id,\n",
    "    \"Document\": {\n",
    "        \"Name\": input_file_name,\n",
    "        \"Base64Content\": encoded_input_file\n",
    "    }\n",
    "}\n",
    "\n",
    "create_job = requests.post(f\"{api_root}/AddDocument\", headers=ai_services_headers, verify=False, json=upload_document_json)\n",
    "response = create_job.json()\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute Job\n",
    "\n",
    "Starts the execution of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_job = requests.post(f\"{api_root}/ExecuteJob?jobId={job_id}\", headers=ai_services_headers, verify=False)\n",
    "response = execute_job.json()\n",
    "print(json.dumps(response, indent=2))\n",
    "\n",
    "status = response[\"Status\"]\n",
    "print(f'The current status of job {job_id} is \"{status}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Poll Job Status\n",
    "\n",
    "Now we watch the job status, hoping for a status of \"Processing\" to change to a status of \"Ready\".\n",
    "\n",
    "This cell will check the job status periodically until the status is no longer \"Processing\".  Note that in some models, certain error cases result in a hanging job that will never update from \"Processing\".  In this case, the cell below will give up after about 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status(jid):\n",
    "    poll_job_status = requests.get(f\"{api_root}/GetJobInformation?jobId={jid}\", headers=ai_services_headers, verify=False)\n",
    "    return poll_job_status.json()\n",
    "\n",
    "wait_time = 10\n",
    "start_time = time.time()\n",
    "duration = 0\n",
    "status = \"Processing\"\n",
    "while status == \"Processing\" and duration < 1800:\n",
    "    response = get_status(job_id)\n",
    "    status = response[\"Status\"]\n",
    "    \n",
    "    clear_output()\n",
    "    duration = int(time.time() - start_time)\n",
    "    print(f\"The current status of job {job_id} is '{status}'.\")\n",
    "    print(f\"{duration} seconds elapsed\")\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    if status == \"Processing\":\n",
    "        time.sleep(wait_time)\n",
    "        wait_time = min(wait_time * 2, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Result\n",
    "\n",
    "Finally, now that the job is complete, we can fetch the results. The results typically come back to us as base64 in a JSON object, which we will need to decode and stuff into a file.\n",
    "\n",
    "Note of course that you don't _have_ to stuff the results into a file, if you've got some other way of using the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_result = requests.get(f\"{api_root}/GetJobSummary?jobId={job_id}&outputFormatId={output_format_id}\", headers=ai_services_headers, verify=False)\n",
    "response = download_result.json()\n",
    "print(json.dumps(response, indent=2)[:128] + \"...\")\n",
    "base64_encoded_output = response[\"Summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A brief note on output formats\n",
    "\n",
    "Pretty much all output formats come back as a base64-encoded file.  The JSON output format is a known exception.  It comes back as JSON.  We don't explore that pure JSON output in this notebook, but suffice it to say you won't be able to decode it as base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    binary_contents = base64.standard_b64decode(base64_encoded_output)\n",
    "except Exception as e:\n",
    "    print(\"I'm having trouble decoding the result from AI Services as base64.  Perhaps you selected an output format of JSON?\")\n",
    "    raise e\n",
    "    \n",
    "with open(OUTPUT_FILE_PATH, \"wb\") as output_file: \n",
    "    output_file.write(binary_contents)\n",
    "\n",
    "print(f\"Job results written to {OUTPUT_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
